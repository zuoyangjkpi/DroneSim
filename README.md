# ğŸš AVIANS ROS2: Autonomous Drone Mission Planning & Tracking System

![ROS2](https://img.shields.io/badge/ROS2-Jazzy-blue) ![Ubuntu](https://img.shields.io/badge/Ubuntu-24.04%20LTS-orange) ![Gazebo](https://img.shields.io/badge/Gazebo-Harmonic-green) ![Python](https://img.shields.io/badge/Python-3.12-blue) ![License](https://img.shields.io/badge/License-Apache%202.0-yellow) ![PX4](https://img.shields.io/badge/PX4-v1.16-red)

## ğŸ“– Project Overview

AVIANS ROS2 is an **end-to-end autonomous drone mission planning, execution, and tracking system** built on ROS2 Jazzy. The stack combines LLM-driven mission planning, YOLO-based target detection, NMPC control, PX4 hardware integration, and Gazebo simulation to deliver a complete autonomous flight workflow from high-level intent to execution.

### ğŸ¯ Key Capabilities
- **ğŸ¤– LLM Mission Planning**: Natural language mission planning powered by large language models
- **ğŸ“‹ Mission Execution Engine**: Behavior-tree inspired YAML mission orchestration framework
- **ğŸ›¸ Advanced Mission Modules**: Takeoff, orbit, search, inspection, landing, and more
- **ğŸ” Real-time Detection**: YOLO v12 deep-learning based target detection
- **ğŸ® NMPC Controller**: Nonlinear model predictive control for precise trajectory tracking
- **ğŸ”— PX4 Hardware Integration**: uXRCE-DDS bridge to Pixhawk 6X flight controllers
- **ğŸ“¹ Visual Servoing**: Camera keeps targets centered during tracking
- **ğŸŒ Physical Simulation**: Gazebo Harmonic high-fidelity simulation environment
- **ğŸ”„ Smart Search**: Automatic scanning rotation when targets disappear
- **ğŸ“Š Live Visualization**: RViz2 state and trajectory visualization

## ğŸ–¥ï¸ System Requirements

### Hardware
- **CPU**: Intel i5 or AMD Ryzen 5 and newer
- **Memory**: Minimum 8 GB (16 GB recommended)
- **GPU**: Dedicated OpenGL-capable GPU recommended
- **Storage**: At least 15 GB of free space

### Software
- **OS**: Ubuntu 24.04 LTS (Noble Numbat)
- **ROS**: ROS2 Jazzy Jalopy
- **Simulation**: Gazebo Harmonic
- **Python**: 3.12+
- **Conda**: Miniconda or Anaconda

## ğŸš€ One-Click Installation (recommended for new machines)

### Automated installer

Use the **fully automated setup script** that installs every dependency:

```bash
# 1. Clone the repo
git clone https://github.com/zuoyangjkpi/AVIANS_ROS2.git
cd AVIANS_ROS2

# 2. Run the one-click installer
chmod +x .setup_avians_ros2_complete.sh
./.setup_avians_ros2_complete.sh

# 3. Reload the environment
source ~/.bashrc

# 4. Validate the installation
./test_avians_complete.sh
```

### Script installs
- âœ… Ubuntu 24.04 updates and base tooling
- âœ… Miniconda + airship_ros2 env (Python 3.12)
- âœ… Full ROS2 Jazzy Desktop
- âœ… Gazebo Harmonic simulator
- âœ… ROS2â€“Gazebo integration packages
- âœ… Python deps (numpy, scipy, opencv, ultralytics, pyyaml, requests, etc.)
- âœ… ONNX Runtime 1.20.1
- âœ… YOLO models and label files
- âœ… Build of 18 ROS2 packages (planning, execution, PX4 bridge, ...)
- âœ… Automatic shell environment configuration
- âœ… Fixes for the "drone not moving" odometry issue

## ğŸ® Quick Start

### Basic workflow

1. **Activate the workspace**
```bash
source ~/.bashrc
cd ~/AVIANS_ROS2
```

2. **Launch the comprehensive test harness**
```bash
./comprehensive_test_suite.sh
```

3. **Pick a test option**
```
ğŸ“‹ Test Options:
1) ğŸ” System Status Check          # System health check
2) ğŸ® Launch Gazebo Simulation     # Start Gazebo simulation
3) ğŸ§  Test YOLO Detector          # Validate YOLO detector
4) ğŸ“¡ Monitor All Topics          # Monitor ROS2 topics
5) ğŸ¯ Full Integration Test       # Complete system test â­ï¸
6) ğŸš NMPC Person Tracking Test   # NMPC person-tracking scenario
7) ğŸ® NMPC + Gazebo Visual        # Visualized tracking demo
8) ğŸ§¹ Kill All ROS Processes      # Clean up ROS processes
```

4. **Option 5** is the recommended end-to-end validation.

### Drone not moving? Try this

If the drone drops or refuses to move, run the pose converter in **another terminal**:

```bash
# Terminal 1: pose converter fixes odometry gaps
cd ~/AVIANS_ROS2
python3 ./pose_to_odom.py &

# Terminal 2: run the main program
./comprehensive_test_suite.sh
# Select option 5
```

## ğŸ—ï¸ Project Architecture

### Core package layout

```
AVIANS_ROS2/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ¤– neural_network_detector/        # YOLO detector
â”‚   â”œâ”€â”€ ğŸš drone_description/              # Drone model & simulation assets
â”‚   â”œâ”€â”€ ğŸ¯ drone_nmpc_tracker/             # NMPC controller
â”‚   â”œâ”€â”€ ğŸ® drone_guidance_controllers/     # Waypoint & yaw controllers
â”‚   â”œâ”€â”€ âš™ï¸ drone_low_level_controllers/    # Low-level velocity adapters
â”‚   â”œâ”€â”€ ğŸ“Š drone_state_publisher/          # State publisher
â”‚   â”œâ”€â”€ ğŸ§  manual_mission_planner/         # LLM-based mission planner
â”‚   â”œâ”€â”€ ğŸ“‹ mission_executor/               # Mission executor engine
â”‚   â”œâ”€â”€ ğŸ›¸ mission_action_modules/         # High-level action modules
â”‚   â”œâ”€â”€ ğŸ”— px4_bridge/                     # PX4 hardware bridge
â”‚   â”œâ”€â”€ ğŸ“¨ custom_msgs/                    # Custom ROS messages
â”‚   â”‚   â”œâ”€â”€ neural_network_msgs/          # Neural-network messages
â”‚   â”‚   â”œâ”€â”€ uav_msgs/                     # UAV messages
â”‚   â”‚   â””â”€â”€ px4_msgs/                     # PX4 message subset
â”‚   â”œâ”€â”€ ğŸ“Š target_tracker_distributed_kf/  # Distributed Kalman tracker
â”‚   â”œâ”€â”€ ğŸ“ projection_model/               # Projection utilities
â”‚   â”œâ”€â”€ ğŸ”„ tf_from_uav_pose/               # TF conversions
â”‚   â”œâ”€â”€ ğŸ“¦ pose_cov_ops_interface/         # Covariance operations
â”‚   â””â”€â”€ ğŸ”§ ros2_utils/                     # Shared ROS2 helpers
â”œâ”€â”€ ğŸ“„ comprehensive_test_suite.sh         # Main test harness
â”œâ”€â”€ ğŸ”§ .setup_avians_ros2_complete.sh      # One-click installer
â”œâ”€â”€ ğŸ pose_to_odom.py                     # Odometry fix script
â”œâ”€â”€ ğŸ“– README.md                           # This guide
â””â”€â”€ ğŸ“– README_SIMULATION.md                # Simulation walkthrough
```

### Key components

| Component | Role | Status |
|-----------|------|--------|
| **LLM Mission Planner** | Natural-language to YAML mission plans | âœ… Stable |
| **Mission Execution Engine** | Behavior-tree style scheduling/execution | âœ… Stable |
| **Mission Action Modules** | Takeoff, search, inspect, land, etc. | âœ… Stable |
| **YOLO Detector** | Real-time detection and bounding boxes | âœ… Stable |
| **NMPC Controller** | Precise nonlinear trajectory tracking | âœ… Stable |
| **PX4 Bridge** | uXRCE-DDS bridge to Pixhawk hardware | âœ… Stable |
| **Waypoint Controller** | Waypoint navigation & yaw control | âœ… Stable |
| **Gazebo Simulation** | 3D physics environment | âœ… Stable |
| **RViz Visualization** | Real-time state/trajectory view | âœ… Stable |
| **Odometry Bridge** | Pose conversion (fixes immobile drone issue) | âœ… Stable |

## âš™ï¸ Detailed Configuration

### 1. YOLO detector

Edit detector parameters:
```bash
# Model path
./src/neural_network_detector/third_party/YOLOs-CPP/models/yolo12n.onnx

# Label file
./src/neural_network_detector/third_party/YOLOs-CPP/quantized_models/coco.names
```

### 2. NMPC controller

Primary config file: `src/drone_nmpc_tracker/drone_nmpc_tracker/config.py`

```python
# Tracking parameters
ORBIT_RADIUS = 3.0          # Orbit radius (m)
ORBIT_HEIGHT = 2.5          # Tracking altitude (m)
SEARCH_ANGULAR_SPEED = 0.5  # Search angular rate (rad/s)

# Control topics
TOPIC_DRONE_STATE = '/X3/odometry'      # Drone state topic
TOPIC_CMD_VEL = '/X3/cmd_vel'           # Velocity command topic
TOPIC_PERSON_DETECTIONS = '/person_detections'  # Detection topic
```

### 3. Gazebo simulation

World config: `src/drone_description/worlds/drone_world.sdf`
- Drone spawn pose: (3, 0, 2.5)
- Camera: 640Ã—480 @ 30 FPS
- Physics: Harmonic with Bullet backend

## ğŸ” How It Works

### System flow

```mermaid
graph TD
    A[Gazebo Simulation] --> B[Camera Frames]
    B --> C[YOLO Detector]
    C --> D[Person Detections]
    D --> E[NMPC Controller]
    F[Drone Pose] --> E
    E --> G[Velocity Commands]
    G --> A
    
    H[pose_to_odom.py] --> F
    A --> H
```

### Control logic

1. **Target detected**
   - Compute relative target pose
   - Plan the orbiting trajectory
   - Keep the camera pointed at the target
   - Maintain the configured orbit radius and altitude

2. **Target missing**
   - Enter the search mode
   - Rotate in place to scan
   - Publish search diagnostics

## ğŸ§ª Testing & Validation

### Test suite options

```bash
./comprehensive_test_suite.sh
```

Available entries:

| Option | Purpose | When to use |
|--------|---------|-------------|
| **1** | System status check | Verify health of all components |
| **2** | Launch Gazebo | Test the simulator alone |
| **3** | YOLO detector test | Validate perception pipeline |
| **4** | Topic monitor | Inspect ROS2 communication |
| **5** | â­ Full integration test | End-to-end validation |
| **6** | NMPC tracking test | Standalone controller test |
| **7** | Visual tracking demo | Graphical demo of the tracker |

### Performance targets

- **Detection latency**: <100 ms
- **Control rate**: 4 Hz
- **Tracking accuracy**: Â±0.5 m
- **Search response**: <2 s
- **Simulation FPS**: 60 FPS

## ğŸ› Troubleshooting

### Common issues

#### 1. Drone drops or will not move
```bash
# Cause: odometry missing
# Fix: run the pose converter
python3 ./pose_to_odom.py &
```

#### 2. RViz fails to open
```bash
# Cause: rendering configuration problems
# Fix: force software rendering
export LIBGL_ALWAYS_SOFTWARE=1
export GALLIUM_DRIVER=llvmpipe
```

#### 3. Missing YOLO models
```bash
# Re-download the YOLO model
cd src/neural_network_detector/third_party/YOLOs-CPP/models/
python3 -c "
from ultralytics import YOLO
model = YOLO('yolov8n.pt')
model.export(format='onnx')
"
```

#### 4. Build failures
```bash
# Clean and rebuild
rm -rf build/ install/ log/
colcon build --symlink-install
```

#### 5. Topic communication issues
```bash
# Inspect ROS2 topics
ros2 topic list
ros2 topic echo /X3/odometry --once
ros2 topic echo /person_detections --once
```

## ğŸ”§ Developer Guide

### Adding features

1. **Expand detection classes**
   - Update YOLO label files
   - Adjust detector config
   - Update control logic

2. **Improve tracking**
   - Tune NMPC parameters
   - Refine trajectory planning
   - Update state estimation

3. **Add new sensors**
   - Extend the Gazebo sensor model
   - Build ROS2 interfaces
   - Update fusion logic

### Code layout reminders

```bash
# C++ package
src/package_name/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ package.xml
â”œâ”€â”€ include/package_name/
â”œâ”€â”€ src/
â””â”€â”€ config/

# Python package
src/package_name/
â”œâ”€â”€ setup.py
â”œâ”€â”€ package.xml
â”œâ”€â”€ package_name/
â””â”€â”€ config/
```

## ğŸ“Š Performance Optimization

### Tuning suggestions

1. **GPU acceleration**
   - Enable CUDA
   - Use the GPU build of ONNX Runtime
   - Optimize allocator/memory usage

2. **Network tuning**
   - Adjust ROS2 QoS profiles
   - Use compressed image transport
   - Tune topic frequencies

3. **Algorithm tweaks**
   - Reduce YOLO input resolution
   - Raise/lower detection confidence thresholds
   - Retune controller parameters

## ğŸ“š API Reference

### Primary topics

| Topic | Message | Description |
|-------|---------|-------------|
| `/camera/image_raw` | `sensor_msgs/Image` | Raw camera frames |
| `/person_detections` | `neural_network_msgs/NeuralNetworkDetectionArray` | Person detections |
| `/X3/odometry` | `nav_msgs/Odometry` | Drone pose/velocity |
| `/X3/cmd_vel` | `geometry_msgs/Twist` | Drone velocity commands |
| `/X3/enable` | `std_msgs/Bool` | Control enable flag |

### Main services

| Service | Type | Description |
|---------|------|-------------|
| `/nmpc/reset` | `std_srvs/Empty` | Reset the NMPC controller |
| `/detector/configure` | `std_srvs/SetParameters` | Update detector parameters |

## ğŸ¤ Contributing

We welcome contributionsâ€”please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing-feature`)
5. Open a pull request

### Coding guidelines
- Follow ROS2 coding conventions
- Add meaningful comments and documentation
- Provide unit tests
- Maintain backward compatibility

## ğŸ“„ License

This project is licensed under Apache License 2.0 â€” see [LICENSE](LICENSE).

## ğŸ™ Acknowledgements

- ROS2 community for the middleware foundation
- Ultralytics for the YOLO implementation
- Gazebo simulator development team
- ONNX Runtime optimization team

## ğŸ“ Support & Contact

- **GitHub Issues**: [Submit an issue](https://github.com/zuoyangjkpi/AVIANS_ROS2/issues)
- **GitHub Discussions**: [Start a discussion](https://github.com/zuoyangjkpi/AVIANS_ROS2/discussions)
- **Technical docs**: See repository guides (MISSION_PIPELINE_PLAN.md, PX4_INTEGRATION_GUIDE.md, ...)

## ğŸ¯ Roadmap

- [ ] Multi-drone collaborative missions
- [ ] Deep-learning-based trajectory prediction
- [ ] Additional PX4 hardware flight-tests
- [ ] Web management console
- [ ] Mobile monitoring app
- [ ] Stronger LLM mission planner

---

<div align="center">

**ğŸš Built for autonomous aerial systems â¤ï¸**

![Demo GIF](https://via.placeholder.com/800x400?text=AVIANS+ROS2+Demo+Video)

*Autonomous target-tracking demo*

</div>

---

## ğŸ“ˆ Release History

### v2.0.0 (current)
- âœ… Complete ROS2 Jazzy port
- âœ… Gazebo Harmonic integration
- âœ… YOLO v12 detection
- âœ… NMPC precision tracking
- âœ… LLM mission planner (Qwen API support)
- âœ… Mission executor + high-level modules
- âœ… PX4 hardware integration (Pixhawk 6X HITL)
- âœ… Waypoint navigation & yaw control
- âœ… One-click installer (18 packages)
- âœ… Full system test suite

### v1.0.0 (initial)
- âœ… Basic person-tracking
- âœ… NMPC orbit tracking
- âœ… Gazebo environment setup

### Coming soon
- ğŸ”„ Real-time trajectory optimization
- ğŸ”„ Multi-target tracking
- ğŸ”„ ML-based trajectory prediction
- ğŸ”„ Multi-drone collaboration
- ğŸ”„ Cloud deployment support
